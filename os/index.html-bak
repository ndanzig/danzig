<!doctype html>
<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" lang="en-US">
<head>
<LINK REL=STYLESHEET HREF="../cpp/style.css" TYPE="text/css">

<title>Operating Systems Course Outline </title>
</head>
<BODY >

<h2>Operating Systems Course Outline</h2>

<h3>Course Requirements </h3>

Full attendance is required. Any lack of attendance will negatively affect your grade and may 
remove your right to a moed bet.  The course is a Pass/Fail course. The text for the course is
<a href=http://codex.cs.yale.edu/avi/os-book/os8c/> Operating Systems 
Concepts, 8th Edition</a> chapters 1 to 9. There are copies of this and previous editions in the school library.
You can use older editions. There will be no assigned homework.  For homework you should read the book.
You can also do any exercises in the back of each chapter.  If you want me to look at your homework, print it and
hand it in to me and I will check it for you. The grade will be determined by your final exam and your attendance.
<br>
<a href="http://www.bhu.ac.in/ComputerScience/vivek/os/studentmanual.pdf">
Student manual for 7th edition </a>

<h3>Long Syllabus</h3>
<hr>
<h4>1. Overview</h4>
<dl>
<dt>physical architecture.
<dt>memory <dd>heap (free memory) code, stack (finite)
<dt>heap<dd>  Large modern OS's will enlarge the heap on demand up to
 available virtual memory (or up to a maximum set by system policy). 
 Default heap size is either set by the OS as policy, or/and at link time,
 or/and can be reserved at runtime by an OS system call.  Depends on the OS.
XP has a default size of 1mb.
<br>
For small embedded OS's where the application and OS are compiled 
together and there is no virtual memory, the heap size is whatever is left
 of RAM after compilation of all code and non-heap data (including the 
stacks' memory, which have to be statically allocated).  The linker is the
 one responsible for this.
<dt>kernel</dt><dd>the one program running all the time providing other programs with services.</dd>
<dt>system calls</dt><dd>requests from software for the kernel to provide a service.</dd>
<dt>Storage Device Hierarchy</dt><dd>From fastest to slowest : registers, cache, main memory, Flash, HD, Optical Disk, tapes.</dd>
<dt>multi processing architecture</dt><dd>Increased throughput(-overhead),  periferal re-use, cheaper, better reliability if one cpu fails (graceful degradation) Solaris uses symetric multiprocessing (ie no master-slave). Dual-core means two CPUs on one cheap.  Faster communication(since it is within a chip) and less power.  Can share registers and cache or not share them. OS sees the dual-core as two processors and therefore must support them. </dd>
<dt>clusters</dt><dd>several systems linked at high speeds (lan)results in high availability (robustness). may be one or more monitoring nodes. clusters can also provide high computation speeds/power.  Beowulf is one such that runs usually on linux.</dd>
<dt>process</dt><dd>program loaded in memory and running.</dd>
<dt>job</dt><dd> program either not yet in memory but ready to be put in memory or a program in memory but not running.</dd>
<dt>virtual memory</dt><dd>method of running a process when only part of it is in main memory.</dd>
<dt>interrupt</dt><dd>signal to OS to stop and do some other action.  Can be from hardware (mouse) or software</dd>
<dt>trap</dt><dd>software generated interrupt. Either by an error or a program request. <dd>
<dt>single programming</dt><dd>CPU works on one process till completion before starting the next process</dd>
<dt>multiprogramming</dt><dd>cpu switches to other process when waiting for I/O.</dd>
<dt>Time sharing (multi-tasking)</dt><dd>
cpu has several processes in memory and gives each a time slice, usually very short. 
It is a good way for a single cpu to appear to be running several processes at the same time. (either for multiple users or multiple programs) If memory is full and no more
processes can be loaded in memory then the OS must decide which processes to load and which not to load.  This is called job scheduling. CPU scheduling is deciding which process to run. This method is very common today but has much overhead, including keeping data separate, swapping and virtual memory, preventing one program from affecting another (malicious).
<dt>user mode and kernel mode</dt><dd>to prevent user software from executing privileged instructions (accessing
 sockets, etc) independently from the OS. When user software requests a service or an interrupt occurs, this
 triggers the operating system to go to kernel mode and provide the service or handle the interrupt. 
If user software tries to access a privileged command the hardware will see that he
is in usermode and refuse, informing the OS. (Hardware support is required) This system allows the OS to
 supervise priveleged instructions and prevent harm.
<dt>timer<dd>one method to limit CPU usage by a process.  Used in conjunction with other methods.
<dt>cache<dd>faster storage memory used temporarily. faster than main memory.  a.k.a. registers  HD ->Mem->cache->hardwareregisters. What happens if a process is timed out while it is still using a register? if the next process overwrites
its cache then the first process will have corrupt data. the OS must prevent this.
<dt>Real-time OS <dd> Application's process priority level may exceed that
 of a system process. App can run in Kernel mode and can block (mask) OS interrupts.
<dt>embedded systems<dd>most are real-time, ex.  car engine. missile controller. Cellphone. Non realtime embedded, DVD
<dt>client server<dd>client makes request, server provides file or service. back and form communication.
<dt> peer to peer</dt><dd>each machine can provide service /files or request them. to discover files/services either 
search a lookup computer or broadcast request and hope for an answer.</dd>
</dl>
<hr>
<h4>2. OS Services and Structure</h4>
<dl>
<dt> OS services</dt><dd>OS Provides: 1.User interface, 2. ability to execute another program, 3.access to I/O 4. File Sytem access, 5. IPC and Networked communication, 6. detection of error in software/hardware. OS should also provide: 1. resource allocation, 2. usage statistics, 3. security and authentication of users / security between processes.
</dd>
<dt>method to command OS directly (without program)<dd>shell interface, GUIs Xerox  
<dt>system calls<dd>a request to OS for a service.   ex in Linux write(). There may be an API between software and OS 
to simplify calling the OS.
<dt>Process Control system call<dd>end, system (run something and return control - require more OS management),
 exec (run and do not return control), fork, set time limit (select) , kill (send signal), locking shared data.
<dt>File Management system calls<dd>open (needed to prevent others from writing),close, delete, read,write,chmod
<dt>Device Management<dd>access devices (disk, screen, keyboard) just as in file.  
<dt>System stats<dd>memory dump, trace (list each system call a process executes),debug  stepping, date
<dt>Communication system calls <dd>IPC 1.message passing (socket, pipe, gethostid, getprocessid)2. shared memory 
<dt>Protection<dd>permissions, setuid
<dt>OS usually comes with some Utilities<dd>explorer, text editor, compiler, browser, control panel
<dt>Design Goals<dd>easy to use, reliable,safe,  fast, easy to maintain, flexible.
<dt>Policy vs Mechanism<dd>design should allow user, admin or software to alter policy (how long to set timer, how much
memory to allocate) Time is a mechanism. Can also design system (like windows) to have no ability to alter policy.  this will give similar look and feel to all computers running windows.
<dt>implementing an OS<dd>OS are written in C usually.  It is close to machine language but allows system to be cross platform. Writing in assembly Language would run faster but be harder to write and platform dependant



<dt>OS Design </dt><dd>1. Just put all the code into one big Kernel program, complex to manage. 2. Use layers from application down to devise driver, organized but slower 3. Micro Kernel (ex. Mach), like layers but fewer layers 4. Modules that are seperate programs that can be linked in at boot or during running. 5. MacOS X uses Mach and bsd as kernel and adda application layer.  In general the more monolithic gives faster results but harder to modify.</dd>

<dt> virtual machines</dt><dd>Guest believes it is running on hardware alone. Requires Hardware support. Each VM guest has
 user and kernel mode, but the whole guest is running in user mode. So when a guest runs a system call, the hardware
 needs to allow it access to the registers and programm counter. Better utilize hardward while still
maintaining seperation between servers. Good for 
sys admins and development </dd>
<dt>simulations/emulations</dt><dd>Wite an entire CPU in software. Translate commands designed for one OS/hardware 
to commands appropriate for another Hardware/OS and pass on to native OS. Much slower than VM. Advantage: not limitted to host's hardware type.   </dd>


<dt>full virtualization<dd> complete virtualization of hardware so that an unaltered OS can run. A key challenge for 
full virtualization is the interception and simulation of privileged operations, such as I/O instructions. The 
effects of every operation performed within a given virtual machine must be kept within that virtual machine, virtual 
operations cannot be allowed to alter the state of any other virtual machine, the control program, or the hardware. 
Some machine instructions can be executed directly by the hardware, since their effects are entirely contained within 
the elements managed by the control program, such as memory locations and arithmetic registers. But other instructions that would "pierce the virtual machine" cannot be allowed to execute directly; they must instead be trapped and simulated. Such instructions either access or affect state information that is outside the virtual machine.
<p>
Full virtualization has proven highly successful for a) sharing a computer system among multiple users, b) isolating users from each other (and from the control program) and c) emulating new hardware to achieve improved reliability, security and productivity.




<dt>vmware</dt><dd> [from wikipedia]
VMware software provides a completely virtualized set of hardware to the guest operating system.
  VMware software virtualizes the hardware for a video adapter, a network adapter, and hard disk adapters. The host provides pass-through drivers for guest USB, serial, and parallel devices. In this way, VMware virtual machines become highly portable between computers, because every host looks nearly identical to the guest. In practice, a system administrator can pause operations on a virtual machine guest, move or copy that guest to another physical computer, and there resume execution exactly at the point of suspension. Alternately, for enterprise servers, a feature called VMotion allows the migration of operational guest virtual machines between similar but separate hardware hosts sharing the same storage. Each of these transitions is completely transparent to any users on the virtual machine at the time it is being migrated.
<p>
VMware Workstation, Server, and ESX take a more optimized path to running target operating systems on the host than emulators (such as Bochs) which simulate the function of each CPU instruction on the target machine one-by-one, or dynamic recompilation which compiles blocks of machine-instructions the first time they execute, and then uses the translated code directly when the code runs subsequently. (Microsoft Virtual PC for Mac OS X takes this approach.) VMware software does not emulate an instruction set for different hardware not physically present. 
This significantly boosts performance, but can cause problems when moving virtual machine guests between hardware
 hosts using different instruction-sets (such as found in 64-bit Intel and AMD CPUs), or between hardware hosts with 
a differing number of CPUs. Stopping the virtual-machine guest before moving it to a different CPU type generally causes
 no issues.
<p>
VMware's products use the CPU to run code directly whenever possible (as, for example, when running user-mode and virtual
 8086 mode code on x86). When direct execution cannot operate, such as with kernel-level and real-mode code, VMware
 products re-write the code dynamically, a process VMware calls "binary translation" or BT. BT automatically modifies
 x86 software on-the-fly to replace instructions that "pierce the virtual machine" with a different, virtual machine
 safe sequence of instructions; this technique provides the appearance of full virtualization. The translated code gets 
stored in spare memory, typically at the end of the address space, which segmentation mechanisms can protect and make
 invisible. For these reasons, VMware operates dramatically faster than emulators, running at more than 80% of the speed
 that the virtual guest operating-system would run directly on the same hardware. In one study VMware claims a 
slowdown over native ranging from 0 to 6 percent for the VMware ESX Server. 
<p>
VMware's approach avoids some of the difficulties of virtualization on x86-based platforms. Virtual machines may deal 
with offending instructions by replacing them, or by simply running kernel-code in user-mode. Replacing instructions
 runs the risk that the code may fail to find the expected content if it reads itself; one cannot protect code against
 reading while allowing normal execution, and replacing in-place becomes complicated. Running the code unmodified in
 user-mode will also fail, as most instructions which just read the machine-state do not cause an exception and will 
betray the real state of the program, and certain instructions silently change behavior in user-mode. One must always 
rewrite; performing a simulation of the current program counter in the original location when necessary and
 (notably) remapping hardware code breakpoints.
<p>
Although VMware virtual machines run in user-mode, VMware Workstation itself requires the installation of various 
drivers in the host operating-system, notably to dynamically switch the GDT and the IDT tables.
<p>
The VMware product line can also run different operating systems on a dual-boot system simultaneously by booting 
one partition natively while using the other as a guest within VMware Workstation.
<p>
Each guest in vmware is contained within one large file.  Copy the file and 
you have a backup of the whole system.
<p>
See <a href="http://www.vmware.com/files/pdf/VMware_paravirtualization.pdf">VMware_paravirtualization.pdf </a>
</dd>

<dt>paravirtualization<dd>The guest OS is altered to make more effecient 
system calls. Cannot be done on proprietary OS like XP
<dt>Partial virtualization<dd>Most but not all of the hardware features are
 simulated, yielding virtual machines in which some but not all software
 can be run without modification. Usually, this means that entire operating 
systems cannot run in the virtual machine - which would be the
 sign of full virtualization - but that many can run.


<dt>hypervisor</dt><dd> Either (1) a software systems that runs 
directly on the host's hardware to control the hardware and to monitor 
guest operating-systems. A guest operating system thus runs on 
another level above the hypervisor (eg. vmware esx server). The hypervisor
acts as an extremely thin host OS. 

Or (2)a software applications running within a conventional
 operating-system environment. Considering the hypervisor layer as a 
distinct software layer, guest operating systems thus run at the third 
level above the hardware. (eg. VMware workstation, VMWare server)
<p>
VMware introduced in 1998 a hypervisor for machines using the Intel x86 
instruction set.
The x86 architecture used in most PC systems poses particular difficulties 
to virtualization. Full virtualization (presenting the illusion of a 
complete set of standard hardware) on x86 has significant costs in hypervisor
 complexity and run-time performance. Recently  CPU vendors have added
 hardware virtualization assistance to their products. Intel's is called 
Intel VT (codenamed Vanderpool) and AMD's is referred to as AMD-V 
(codenamed Pacifica). These extensions address the parts of x86 that are
 difficult or inefficient to virtualize, providing additional support to the 
hypervisor. This enables simpler virtualization code and a higher performance
 for full virtualization.
<p>
An alternative approach requires modifying the guest operating-system to
 make system calls to the hypervisor, rather than executing machine
 I/O instructions which are then simulated by the hypervisor. This is called
 paravirtualization in Xen, a "hypercall" in Parallels Workstation, and
 a "DIAGNOSE code" in IBM's VM. VMware supplements the slowest rough corners
 of virtualization with device drivers for the guest. All are really the
 same thing, a system call to the hypervisor below. Some microkernels
 such as Mach and L4 are flexible enough such that "paravirtualization" 
of guest operating systems is possible.
<p>
Others, like Xen, implement software-only virtual machines. Xen runs on a 
normal host operating system such as Linux, and is able to run both
 paravirtualized and fully virtualized (i.e., unmodified) operating systems with the help of the hardware virtualization extensions Intel VT-x. The Xen distribution already contains versions of FreeBSD, Linux, NetBSD, and Plan 9 from Bell Labs that have been so modified. User programs will continue to work on Xen without change. Also, Xen has been re-implemented on the OpenSolaris operating system as of build 75 

</dd>
<dt>JVM<dd>Java virtual machine make java code cross platform.  The JVM acts
as the OS for running java byte code and translated the code/system calls to
 the underlying machine language at run time. Alternitively, there may be a
chip built-in for running byte-code. just-in-time compilation means that a
function can be translated when first needed and referred to later when needed again without having to retranslate it.

<dt>Bootstrap program</dt><dd>Paradox: Before the OS is up, the computer needs to load it. But without a OS computer can't run. Solution: a small piece of 
code in EPROM  that locates and loads the kernel into memory.  Before loading however, it usually runs diagnostics and initializes registers. The Bootstrap may load a boot block which in turn loads the kernel or it itself may directly load the kernel.  Saving EPROM is a consideration. Ex. of a bootstrap program: GRUB</dd>
<dt>firmware<dd>ROM, EPROM.  Cellphones use firmware for entire OS. Slower than RAM.

</dl>
<hr>

<h4>3. Processes</h4>

<dl>

<dt>process composition<dd>value of program counter, register values, <em>stack</em> of temporory data like  (function params and 
values), data section (globals), heap (dynamically allocated memory).
<dt>process states<dd>new, running, waiting(waiting for an event to occur), ready (waiting to get CPU), terminated (zombie).

<dt>process control block (PCB) <dd>represents process in OS. contains: process state, program counter, CPU registers (ex. 
accumulators), process priority, memory location, stats on the process,  list of I/O assigned to process, info on threads.



<dt>process  scheduling</dt><dd>on multiprocess machines, the goal is have some process running at all times. Uses a 
scheduling queue</dd>
<dt>Job queue<dd>all processes on system.
<dt>ready queue<dd> processes (PCB) in memory and waiting to execute

<dt>device queue<dd>list of processes waiting for a particular device (I/O) . The device may be busy executing something from another process.
<dt>queueing diagram<dd> show an example of one. Page 108
<dt>dispatching<dd>selecting a process for execution.
<dt>I/O Bound <dd>process which spends most of its time doing I/O
<dt>CPU Bound <dd>process which spends most of its time doing computations
<dt>scheduler<dd>OS element that determines which process gets the CPU next.
There is a short term scheduler and a longer term one.  Logterm has more time
 to decide which processes to make ready.
Long term Scheduler should pick a mix of CPU and I/O bound processes to make ready.
Windows and UNIX have no longterm  scheduler.  All processes are made ready for the short term scheduler to access.
<dt>swapping<dd>when the medium term scheduler decided to temporarily remove
 one process from memory and from the ready queue, to lighten the load for 
other processes.
<dt>Context<dd>PCB (CPU register values,process state,memory locations)
<dt>context switch<dd>storing the context of a process so another
process can be run. State save and state restore. Takes a few milliseconds, but takes longer for a more complex OS.
<dt>Process creating<dd> Parent forks child and so on. Parent gets PID of child. init
Child's resources may be a subset of the parent's or may be external, provided by the OS.
Parent can pass data to child at initialization, eg. a file name to be opened. 
Parent may stop running until child(ren) finish, or it may run concurrently.
Child might run an exec command , thus replacing his memory image. 
<dt>UNIX fork<dd>returns 0 to child process and CPID to parent process.  Parent variables
are recreated in child and both processes continue executing from point after the fork. Show code example.
<dt>process termination</dt><dd>child runs exit() to end and OS  deallocated all system resourced. 
Exit value is returned to parent. Parent can allso "kill" child  using the CPID and kill(). In 
UNIX if a parent dies before child, init become the new parent. Parent can pause by wait()ing 
for a child to terminate. It can also waitpid() for a specific child. If parent does not wait 
and a child dies, it becomes a "zombie" and the OS stores its exit value for any future wait.




<dt>Inter Process Communication (IPC)<dd>processes can be  totally independent if they have no way to affect each other.
If they are intended to work together they must communicate either via (1)shared memory or (2) Message passing. </dd>
<dt>pros and cons of message passing and shared memeory<dd> 
mp better for small data transfer, no mutex needed. mp easier than sm when 
you need intercomputer comm.  sm requires only a one time system call,
 unlike mp , is faster  than mp but requires mutex/semaphore.

<dt>Creating SH<dd>system call to get memory, then each must attach to it.
Need to prevent simultaneous accessing.
<dt>Producer-Consumer<dd>produces info, uses info. Web server - browser.
Compiler - assembler. Both could access one buffer.  Need to maintain 
pointers to know when full or empty. (bounded and unbounded buffers). 
 Also need mutex/semaphore to prevent simultaneous accessing.

<dt>Message Passing Addressing<dd> You can either send to/
receive from  a specific process
or to a port/mailbox.  The latter scheme is more versatile since any process
may then communicate with you, via the port.
<dt>MP Blocking<dd> If eihter side (sender or receiver) waits for message to
 be accepted by the other side before sending more, we call that blocking.
MP can be blocked on one side , or both, or neither side.  Also called
asynchronous and synchronous MP.
<dt>buffering<dd> the OS must buffer  messages for the processes if the sender is non-blocking.

<Dt>Show example of SH<dd> See my unix lab website

<dt>Sockets<dd> end-point of communication. 65,535 on a PC.  Well Known 
ports, TCP (COP)  UDP (CLOP). Client initiates connection, uses IP.
 <dt>Remote Procedure Calls (RPC)<dd>
Use a specific port on another machine (server) to execute an associated 
command.  More structured than sockets.  Need to deal with network packet
 duplications to achieve "exactly once" command execution.  First implement 
"at most once" by sending timestamps and storing a history in the server. Repeated commands are thrown out.  Then use ACKs sent from the server to verify
 that the command reached the server. Client resends until he gets and ACK.
<dt>pipe<dd> system resource
 designed to allow communication between processes on one computer.

<dt>ordinary pipe (or "anonymous pipes" in Windows)<dd>A pipe which allow producer consumer communication.  One side write, other side reads, unidirectional.  A second pipe would be needed for reverse communication.  Unix use read() and write() commands like files. Used in Parent-child process relationships.
Examples are in the Unix Lab. Non reading process should close its reading side of the pipe. Non writing side of the pipe should close its writing side of the pipe.

<dt>Named pipes<dd> bi-directional pipes that exist independently of other processes.  Many processes can use them simultaneously. In UNIX they are called FIFOs , mkfifo(), and are half-duplex. In Windows named pipes are full
 duplex and can allow intercomputer communication.




</dl>

<hr>
<h4>4. Threads</h4>
<dl>
<dt>thread<dd>a light weight process. It contains thread ID, a program counter
a register set and a stack.  But it only shares with its parent its code section, data section, os resources like open files.  

<dt>multithreading<dd>a process consisting of more than one thread.  Theoritcally allows for parallel processing.

A webserver may create a new process for each connection , but it is less
overhead and time consuming to use threads, especially since each thread uses the same code anyway. A web browser could be multi-process or multithreaded.  Either way , it would then be able to let the user do several tasks simultaneously.

<dt>benefits of multithreading<dd>1. better application responsiveness 
2. by default resources are shared allowing simpler IPC than processes 
3. Faster creation time than processes
4. allows full utilization of a multi-CPU machine or multi-core machines.

<dt>Considerations when designing software to be run in parallel
<dd>1.Divide application into part that can be run in parallel. 
2.Ensure these part are equally time consuming and valuable to eachother.
3.Make sure data access is not conflicting
4.Synchronized threads that need to be.
5.Determine how to test it.
<dt>[User Thread : Kernel thread] Relationship <dd>Kernel threads are managed by the OS, user threads are managed by the
 program.  When a user creates a thread there needs to be a kernel thread in the OS which will correspond to it and
actually do the work. 
The relationship between a number of user threads and the kernel threads can be either 
many to one, one to one or many to (<=)  many. 
n:1 permits programmer to create as many threads as he desires, 
but does not provide true parallelism.  One blocked thread will block others.
1:1 provides true parallelism but limits programmer to to finite number of 
threads since each user thread will create one new kernel thread.
Best is n:n, then the OS can decide when to create new kernel threads and when not to.
<dt>pthreads<dd> POSIX standardwhich defines, specifies an API for thread creation and synchronization.
Many implementations exist, Solaris, Mac, Linux, even third party software for Windows.

</dl>
<hr>
<h4>5. Process Scheduling</h4>
<dl>
<dt>Process Scheduling goal     <dd>to have CPU utilized all the time. Several processes are in memory, scheduler decides which should get the CPU. 
<dt>CPU Burst Cycle<dd>Large number of short burst of CPU use, small number of longer bursts. I/O bound processes tend to have more and shorter bursts.


<dt>short-term scheduler     <dd>when CPU is Idle (or at other times too),
 this scheduler selects a process to run from the ready queue. Ready queue need not be a fifo. 
<dt>When does ST Scheduler act?<dd>1. A Process becomes idle(wait for child, or I/O) 2.Process halted by a signal/interrupt 3. When a processes stops waiting and become ready again 4. when a process terminates.
<dt>Non-Preemptive or cooperative Scheduling     <dd> Scheduler act only in cases 1 and 4 above. When a process gets CPU it keeps it for as long as it wants (Windows 3.x)
<dt>Preemptive Scheduling     <dd>Scheduler acts in all 4 cases.  More complex and creates a critical area problem . Also what if Kernel is in the middle of a request from a process when the process is preempted?  Linux waits for the kernel to finish, but this is not good for some aplications (real-time). Also need to prevent an interrupt occuring in the middle of another interrupt.  Can cause data corrupting.  therefore interrupts usually block other interrupts.

<dt>Dispatcher     <dd>Gives CPU to process selected by scheduler. needs to switch context, switch to user mode, jumpt to program counter location.
<dt>Dispatch Latency     <dd>time it take to stop one process and start another. 

<h4>Measures of Scheduling Algoritms - how to gauge an algorithm  </h4>
<blockquote><dt>CPU Utilization     <dd>percent of time CPU is active

<dt>Throughput     <dd>how many processes are completed per hour.

<dt>Turnaround time     <dd>How long a given process takes to complete (on a busy system) 

<dt>Waiting Time     <dd>total Time spent in ready queue (perhaps the best measure since cpu time is not determined by the scheduler.)

<dt>Response time <dd>time it takes from process start to when first output 
starts to be printed. This measure is independent of the output device's
 speed.
 </blockquote>
We may want to optimize the average values for these gauges 
or the maxes or mins .  We may also want to minimize the variance so we can have a predictable response time.




<h4> Scheduling Algorithms</h4>
<dt>Gantt Chart<dd>bar chart use for comparing algorithms. Process in order are represented showing burst time by length.
<pre>
__________________________________
| P1                  | P2  | P3  |
----------------------------------
0                     14    17    20
</pre>
Average Wait time is  (0+14+17)/3 = 10.3

<dt>First-Come, First-Served      <dd>Easy to implement, FIFO. But the order
 that processes arrive can strongly affect average wait time.
 Drawback also if there is one CPU bound Process, it may force other I/O bound processes to wait for it each time, <b>convoy effect</b>. Preempting based on time slice can help alleviate this, though this algorithm is usually considered to be non-preemptive.

<dt>Shortest Job First            <dd>Need to know the length of the next CPU
 burst of each process, then assign the shortest to the top of the queue (use fcfs to break ties). Gantt chart show this to have optimal average wait time, but can cause a long process to "starve".  Also How to comute next cpu burst? 
We could try to predict it based on past behavior. Compute an exponential 
average.

<p>Let t<sub>n</sub>
 be the length of the nth CPU burst, and let &tau;<sub>n+1</sub> be our predicted value for the next cpu burst. Then, for &alpha;,  0 &le;&alpha;&le;1, define
<blockquote> &tau;<sub>n+1</sub> = &alpha;&tau;<sub>n</sub> + (1- &alpha;)&tau;<sub>n</sub>
</blockquote>
 &tau;<sub>n</sub> stores past history, t<sub>n</sub> contains the most recent CPU burst history .
Changing the value we assign to &alpha; changes the relative weight recent 
and distant history has.
If we preempt a process when a shorter one arrives we call this a
 <b>shortest remaining time first</b> algorithm. 

<dt>            <dd>
 Question for thought.  When a process is switched out because of I/O when it is ready, where does it go in the queue, back to the top or to the end?

<dt>            <dd>
 

<dt>            <dd>
 

<dt>            <dd>
 

<dt>            <dd>
 


</dl>

<hr>

<dl>
<dt>vxworks<dd>a popular embedded real time OS, but more and more popular to use a Linux  on an embedded system. 
<dt>soft real time<dd>timing important but time failure will not cause everything to be worthless. ex. VOIP
<dt>hard real time<dd>time failure causes system to be useless,worthless. Ex. Missile System
<dt>interrupts on VMWare client<dd>should be slowed down or turned off because otherwise host is spending all time supplying the interrupts and client (guest) will run slow. When you set up a VMWare machine you set its disk size  and memory.  these should be less than host, even if you plan to run only one guest.
</dd>
</dl>

<p>
&copy; Nachum Danzig 2010
</body>
</html>




